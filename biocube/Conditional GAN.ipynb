{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b19e2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b03ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan():\n",
    "    \n",
    "    # Generator network\n",
    "    generator = models.Sequential()\n",
    "    generator.add(layers.Dense(256, activation='relu', input_dim=101))  # 101 is the total dimension after concatenation\n",
    "    generator.add(layers.Reshape((8, 8, 4)))\n",
    "    \n",
    "    generator.add(layers.Conv2DTranspose(316, (5, 5), strides=(1, 1), padding='same', activation='relu'))\n",
    "    generator.add(layers.BatchNormalization())\n",
    "    \n",
    "    generator.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', activation='relu'))\n",
    "    generator.add(layers.BatchNormalization())\n",
    "    \n",
    "    generator.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', activation='relu'))\n",
    "    generator.add(layers.BatchNormalization())\n",
    "    \n",
    "    generator.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu'))\n",
    "    generator.add(layers.BatchNormalization())\n",
    "    \n",
    "    generator.add(layers.Conv2DTranspose(1, (5, 5), strides=(4, 4), padding='same', activation='tanh'))\n",
    "\n",
    "    # Discriminator network\n",
    "    discriminator = models.Sequential()\n",
    "    discriminator.add(layers.Input(shape=(256, 256, 1)))\n",
    "    \n",
    "    discriminator.add(layers.Conv2D(64, (5, 5), strides=(1, 1), padding='same', activation='relu'))\n",
    "    discriminator.add(layers.BatchNormalization())\n",
    "    \n",
    "    discriminator.add(layers.Conv2D(128, (5, 5), strides=(1, 1), padding='same', activation='relu'))\n",
    "    discriminator.add(layers.BatchNormalization())\n",
    "\n",
    "#     discriminator.add(layers.Flatten())\n",
    "    discriminator.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "\n",
    "# Define user ID and noise input layers\n",
    "user_id_input = layers.Input(shape=(1,), dtype=tf.int32)\n",
    "noise_input = layers.Input(shape=(100,))\n",
    "\n",
    "# Create cGAN model\n",
    "generator, discriminator = build_cgan()\n",
    "\n",
    "# Define loss functions and optimizers for generator and discriminator\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = Adam(1e-4)\n",
    "discriminator_optimizer = Adam(1e-4)\n",
    "\n",
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "NUM_USERS = 10\n",
    "\n",
    "# Training loop\n",
    "@tf.function\n",
    "def train_step(images, user_ids):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "    user_id_float = layers.Lambda(lambda x: tf.cast(x, tf.float32))(user_ids)\n",
    "    user_id_float = tf.reshape(user_id_float, (BATCH_SIZE, 1))\n",
    "    # print(noise.shape, user_id_float.shape)\n",
    "    concatenated_inputs = tf.concat([user_id_float, noise], axis=1)  # Concatenate user ID and noise\n",
    "    # print(concatenated_inputs.shape)\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(concatenated_inputs, training=True)\n",
    "        # print(generated_images)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fdebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               26112     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 4)           0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 316)        31916     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 8, 316)        1264      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 256)      2022656   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 128)      819328    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 64)       204864    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 256, 256, 1)      1601      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,109,533\n",
      "Trainable params: 3,108,005\n",
      "Non-trainable params: 1,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9899dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 64)      1664      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256, 256, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 128)     204928    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256, 256, 128)    512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256, 256, 1)       129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,489\n",
      "Trainable params: 207,105\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5cbf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "augmented_data_folder = r'datasets\\augmented_jabcode'\n",
    "\n",
    "NUM_USERS = 10\n",
    "NUM_IMAGES_PER_USER = 10\n",
    "\n",
    "# Initialize empty lists to store user data and user IDs\n",
    "user_data = []\n",
    "user_ids = []\n",
    "\n",
    "# Loop through the folders for each user\n",
    "for user_id in range(1, NUM_USERS + 1):\n",
    "    user_data_folder = os.path.join(augmented_data_folder, f'user_{user_id}')\n",
    "    \n",
    "    user_images = []  # To store images for the current user\n",
    "    user_id_array = np.array([user_id] * NUM_IMAGES_PER_USER, dtype=np.int32)  # User IDs for the current user\n",
    "    \n",
    "    for image_id in range(NUM_IMAGES_PER_USER):\n",
    "        image_filename = f'jabcode_user_{user_id}_augmented_{image_id}.png'\n",
    "        image_path = os.path.join(user_data_folder, image_filename)\n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale image\n",
    "        image = cv2.resize(image, (256, 256))  # Resize if needed\n",
    "        image = np.reshape(image, (256, 256, 1))\n",
    "        # print(image.shape)\n",
    "        user_images.append(image)\n",
    "    \n",
    "    user_data.append(user_images)\n",
    "    user_ids.append(user_id_array)\n",
    "\n",
    "# Now you have user_data, a list of lists containing user-specific images, and user_ids, a list of user IDs corresponding to each user's images.\n",
    "\n",
    "# You can use these arrays to train your cGAN.\n",
    "\n",
    "# Assuming you have already loaded and organized your data as user_data and user_ids\n",
    "\n",
    "# Create a user ID to condition mapping\n",
    "user_ids_mapping = {}\n",
    "for i in range(NUM_USERS):\n",
    "    user_ids_mapping[i] = np.array([i] * BATCH_SIZE, dtype=np.int32)\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    for user_id in range(NUM_USERS):\n",
    "        for batch_images in user_data[user_id]:\n",
    "            train_step(batch_images, user_ids_mapping[user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ebfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
